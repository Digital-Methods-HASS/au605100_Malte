---
title: "Homicides by state"
author: "Adela Sobotkova"
date: "20 July 2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Goal
I want to be able to compare and contrast the homicide rates per state as found in wikipedia https://en.wikipedia.org/wiki/List_of_U.S._states_by_homicide_rate (1996-2018), FBI regional violent crime data per state in 2017-2018 (https://ucr.fbi.gov/crime-in-the-u.s/2018/crime-in-the-u.s.-2018/topic-pages/tables/table-4 and https://ucr.fbi.gov/crime-in-the-u.s/2018/crime-in-the-u.s.-2018/topic-pages/tables/table-5 )  with police shootings from 2013-2020 (july 2020) that are nicely collated on summarised on .

# Challenge
The wikipedia data resides in the HTML table that has notoriously messy headers and tags. 

But fear not! There’s nothing that R can’t fix in a blink of an eye. And here’s how:

Great guidelines to finding the right tags are in [rvest tutorial on Youtube](https://www.youtube.com/watch?v=4IYfYx4yoAI)


# Solution
First, load a handful of classic R packages:

{rvest} for web-scraping
{dplyr} for data-wrangling
{tidyr} for data transformation
{stringr} for string manipulation
{janitor} for clean headers that your OCD will love you for


```{r libraries}
library(tidyverse)
library(rvest)
library(dplyr)
library(tidyr)
library(stringr)
library(janitor)
```


## Scrape the data

Next, learn how scrape the content of the website and extract the HTML table:
```{r}
url <- "https://en.wikipedia.org/wiki/List_of_U.S._states_by_homicide_rate"
# scrape the website
url_html <- read_html(url)

# extract the HTML table through the <table> tag >> this creates a list instead of dataframe, but we can unlist a list and coerce it into a dataframe, so vaersgo!
whole_table <- url_html %>% 
 html_nodes("table") %>%
 html_table()  #str(whole_table) turns out to be a list

homicide_rate_wiki <- do.call(cbind.data.frame,whole_table) # much better solution as it does not force every thing to a character, but preserves different datatye
head(homicide_rate_wiki) # ok, looks good, and it took 3 minutes
# columns contain rates per 100,000 inhabitants per year

```
# Clean up

```{r}
homicide <- homicide_rate_wiki[,c(1,8,7,6,5,4,3,2)]
homicide
```


# Lets look at some charts

```{r}

library(ggrepel)

homicide <- homicide %>% 
  pivot_longer(-State, names_to = "year", values_to = "rate100k")
homicide$year <- as.numeric(homicide$year)  # to stop ggplot from acting up over character column
homicide

ggplot(homicide,
       aes(year,
           rate100k*10,
           colour = State)) +
  geom_line() +
	expand_limits(x=c(1994, 2022)) +
  geom_text_repel(data = homicide[homicide$rate100k > 7.5 & homicide$year == 2018,],
           aes(label = State,
               x = 2018.1, 
               y = rate100k*10, 
               colour = State, 
               hjust = -.01)) +
  theme_minimal()  +
  ylab("Number of people killed per 1,000,000") +
  xlab("Year") +
  theme(legend.position="none")
  
```

```{r}
by_state_hom18 <- homicide %>% 
  filter(year == 2018) %>% 
	group_by(State) %>% 
  left_join(state_abb, by = c('State' = 'state_name')) 


ggplot(by_state_hom18, 
       aes(state = state_abb, 
           fill = rate100k)) +
  geom_statebins() +
  coord_equal() +
  scale_fill_viridis() +
  theme_statebins() +
  labs(title = "Number of homicides in each state in 2018,\nper 1,000,000 people")  +
  theme(legend.title=element_blank())
```

